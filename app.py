import streamlit as st
from transformers import pipeline
from PIL import Image
import pandas as pd

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°",
    page_icon="âœ¨",
    layout="wide"
)

# 2. ì œëª©
st.title("AI ë§ŒëŠ¥ ì´ë¯¸ì§€ ë¶„ë¥˜ê¸°")
st.markdown("""
ì—¬ëŸ¬ ì¥ì˜ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ë¶„ì„í•˜ê±°ë‚˜, ì¹´ë©”ë¼ë¡œ ì°ì–´ì„œ ë°”ë¡œ í™•ì¸í•´ë³´ì„¸ìš”!  
(Model: Google ViT-Base / ImageNet-1k)
""")

# 3. ëª¨ë¸ ë¡œë”© (ìºì‹±)
@st.cache_resource
def load_model():
    classifier = pipeline("image-classification", model="google/vit-base-patch16-224")
    return classifier

with st.spinner("AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
    classifier = load_model()

# ê³µí†µ ë¶„ì„ í•¨ìˆ˜
def analyze_image(image_obj):
    # 2ë‹¨ ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ
    col1, col2 = st.columns([1, 1.5])
    
    with col1:
        st.image(image_obj, caption="Input Image", width=350)
    
    with col2:
        # ëª¨ë¸ ì¶”ë¡  (ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ë²„íŠ¼ ì—†ì´ ë°”ë¡œ ì‹¤í–‰í•˜ë„ë¡ ë³€ê²½)
        results = classifier(image_obj)
        top_result = results[0]
        label = top_result['label']
        score = top_result['score']
        
        # ì´ëª¨ì§€ ë§¤í•‘
        emoji = "ğŸ¤–"
        if "dog" in label or "retriever" in label or "terrier" in label:
            emoji = "ğŸ¶"
        elif "cat" in label or "tabby" in label:
            emoji = "ğŸ±"
        elif "car" in label or "vehicle" in label:
            emoji = "ğŸš—"
        elif "coffee" in label or "cup" in label:
            emoji = "â˜•"
        elif "food" in label or "burger" in label or "pizza" in label:
            emoji = "ğŸ”"
        
        st.success(f"{emoji} **[{label}]** ({score*100:.1f}%)")
        
        # ì°¨íŠ¸ ì‹œê°í™”
        df = pd.DataFrame(results)
        df['score'] = df['score'] * 100 
        
        st.bar_chart(
            df.set_index('label')['score'],
            color=["#FF4B4B"],
            height=200 # ì°¨íŠ¸ ë†’ì´ ì¡°ì ˆ
        )

# 4. íƒ­ êµ¬ì„±
tab1, tab2 = st.tabs(["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ (ì—¬ëŸ¬ ì¥ ê°€ëŠ¥)", "ğŸ“¸ ì¹´ë©”ë¼ ì´¬ì˜"])

# íƒ­ 1: íŒŒì¼ ì—…ë¡œë“œ
with tab1:
    uploaded_files = st.file_uploader(
        "ì´ë¯¸ì§€ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)", 
        type=["jpg", "jpeg", "png"], 
        accept_multiple_files=True 
    )
    
    if uploaded_files:
        st.write(f"ì´ {len(uploaded_files)}ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
        
        # ë²„íŠ¼ í•˜ë‚˜ë¡œ ì¼ê´„ ë¶„ì„ ì‹œì‘
        if st.button("ì „ì²´ ë¶„ì„ ì‹œì‘", type="primary"):
            # ë°˜ë³µë¬¸(for)ìœ¼ë¡œ íŒŒì¼ í•˜ë‚˜í•˜ë‚˜ êº¼ë‚´ì„œ ë¶„ì„
            for file in uploaded_files:
                st.divider() # êµ¬ë¶„ì„ 
                image = Image.open(file)
                analyze_image(image) # ìœ„ì—ì„œ ë§Œë“  í•¨ìˆ˜ í˜¸ì¶œ

# íƒ­ 2: ì¹´ë©”ë¼ ì´¬ì˜
with tab2:
    camera_file = st.camera_input("ì§ì ‘ ì‚¬ì§„ì„ ì°ì–´ë³´ì„¸ìš”!")
    if camera_file:
        st.divider()
        image = Image.open(camera_file)
        analyze_image(image) # í•¨ìˆ˜ ì¬ì‚¬ìš©